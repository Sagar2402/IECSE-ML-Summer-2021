{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic Dataset DNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOQOD0roXmUjRLhw90jfV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagar2402/IECSE-ML-Summer-2021/blob/AkshatBhandari-1/Titanic_Dataset_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6hFbmWxKfC1"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99OireW1NTtU"
      },
      "source": [
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Ns0aGzNWDh",
        "outputId": "cfe32f59-3caf-4397-db04-2af4264f0b61"
      },
      "source": [
        "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
            "16384/13049 [=====================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4HIAbe2NhLF"
      },
      "source": [
        "titanic_train_set = tf.data.experimental.make_csv_dataset(\n",
        "    titanic_file_path,\n",
        "    batch_size=12,\n",
        "    label_name='survived',\n",
        "    num_epochs=1,\n",
        "    ignore_errors=True)\n",
        "\n",
        "titanic_test_set = tf.data.experimental.make_csv_dataset(\n",
        "      test_file_path,\n",
        "      batch_size=12, \n",
        "      label_name='survived',\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBzDBgypNjho",
        "outputId": "4054570f-5a42-4d5b-e94f-986ab4274e25"
      },
      "source": [
        "for batch, label in titanic_csv_ds.take(1):\n",
        "  for key, value in batch.items():\n",
        "    print(f\"{key:20s}: {value}\")\n",
        "  print()\n",
        "  print(f\"{'label':20s}: {label}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'female' b'male' b'male' b'female' b'male' b'male'\n",
            " b'male' b'female' b'female' b'female']\n",
            "age                 : [10.  28.  44.  28.  55.5 14.  14.  39.  19.  28.  14.  28. ]\n",
            "n_siblings_spouses  : [3 0 0 0 0 1 5 0 0 1 1 0]\n",
            "parch               : [2 0 1 0 0 0 2 0 0 0 0 0]\n",
            "fare                : [27.9    13.8625 57.9792  7.8958  8.05   11.2417 46.9    13.      8.05\n",
            " 15.5    30.0708  7.2292]\n",
            "class               : [b'Third' b'Second' b'First' b'Third' b'Third' b'Third' b'Third' b'Second'\n",
            " b'Third' b'Third' b'Second' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'B' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Cherbourg' b'Cherbourg' b'Southampton' b'Southampton'\n",
            " b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Queenstown'\n",
            " b'Cherbourg' b'Cherbourg']\n",
            "alone               : [b'n' b'y' b'n' b'y' b'y' b'n' b'n' b'y' b'y' b'n' b'n' b'y']\n",
            "\n",
            "label               : [0 1 1 0 0 1 0 0 0 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2T66FqBN9DM"
      },
      "source": [
        "CATEGORIES = {\n",
        "    'sex': ['male', 'female'],\n",
        "    'class' : ['First', 'Second', 'Third'],\n",
        "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
        "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
        "    'alone' : ['y', 'n']\n",
        "}\n",
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RSHFedpb6ia"
      },
      "source": [
        "def process_continuous_data(mean, data):\n",
        "  # Normalize data\n",
        "  data = tf.cast(data, tf.float32) * 1/(2*mean)\n",
        "  return tf.reshape(data, [-1, 1])\n",
        "\n",
        "MEANS = {\n",
        "    'age' : 29.631308,\n",
        "    'n_siblings_spouses' : 0.545455,\n",
        "    'parch' : 0.379585,\n",
        "    'fare' : 34.385399\n",
        "}\n",
        "\n",
        "numerical_columns = []\n",
        "\n",
        "for feature in MEANS.keys():\n",
        "  num_col = tf.feature_column.numeric_column(feature, normalizer_fn=functools.partial(process_continuous_data, MEANS[feature]))\n",
        "  numerical_columns.append(num_col)\n",
        "\n",
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numerical_columns)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utx65cTsOIWr"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer,\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLjja257OIRJ",
        "outputId": "8f3f3332-f570-4712-cbbd-7dcf9614c10e"
      },
      "source": [
        "train_data = titanic_train_set.shuffle(500)\n",
        "test_data = titanic_test_set\n",
        "model.fit(train_data, epochs=20)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>), ('age', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int32>), ('parch', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int32>), ('fare', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>), ('class', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>)])\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>), ('age', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int32>), ('parch', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int32>), ('fare', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>), ('class', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>)])\n",
            "Consider rewriting this model with the Functional API.\n",
            "53/53 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7352\n",
            "Epoch 2/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8054\n",
            "Epoch 3/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8182\n",
            "Epoch 4/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8262\n",
            "Epoch 5/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8214\n",
            "Epoch 6/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8150\n",
            "Epoch 7/20\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8373\n",
            "Epoch 8/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8437\n",
            "Epoch 9/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8373\n",
            "Epoch 10/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8453\n",
            "Epoch 11/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8405\n",
            "Epoch 12/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8389\n",
            "Epoch 13/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8421\n",
            "Epoch 14/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8485\n",
            "Epoch 15/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8533\n",
            "Epoch 16/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8533\n",
            "Epoch 17/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8517\n",
            "Epoch 18/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8517\n",
            "Epoch 19/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8612\n",
            "Epoch 20/20\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feccca9b7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9F-nAUN-fTv",
        "outputId": "988d7e29-01ec-4b70-f839-0e2a21345e19"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>), ('age', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int32>), ('parch', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int32>), ('fare', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>), ('class', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>)])\n",
            "Consider rewriting this model with the Functional API.\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8k8pvoA-cJn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxqxaWMUNhAm"
      },
      "source": [
        ""
      ]
    }
  ]
}